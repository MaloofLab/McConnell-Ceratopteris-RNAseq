---
title: "Map Reads NCBI"
author: "Julin Maloof"
date: "2025-03-31"
output: html_document
---

```{r}
library(tidyverse)
```


## Index the genome

Ran out of memory on medium size instance, try large.  Ran out of memory on large, try XXL
```{bash}
cd /analyzed_data/ref_genomes/C_richardii_v2.1

STAR \
    --runThreadN 7 \
    --runMode genomeGenerate \
    --genomeDir star_index \
    --sjdbOverhang 149 \
    --sjdbGTFfile annotation/Crichardii_676_v2.1.gene_exons.gff3 \
    --sjdbGTFtagExonParentTranscript Parent \
    --genomeFastaFiles assembly/Crichardii_676_v2.0.fa
```

## map the reads

What is the intron size distribution?

Note: Need to run an XL instance because of memory requirements with this large genome


```{bash}
conda activate sequencing

fastq_dir=/media/volume/julin-scratch/fastqs/
index_dir=/analyzed_data/ref_genomes/C_richardii_v2.1/star_index
out_dir=/media/volume/julin-scratch/bams

rm -r $out_dir/*

cd $fastq_dir

# samples with paired reads
R1_files=$(ls *_1.fastq)

for f1 in $R1_files
  do
    f2=$(echo $f1 | sed s/_1/_2/) # read pair 2
    out_file=$(basename $f1 $fastq)_P_
    echo $(date) $f1 ">" $out_file 
    # map the paired reads
    STAR --runThreadN 28 \
      --genomeDir $index_dir \
      --readFilesIn $f1 $f2 \
      --outFileNamePrefix $out_dir/$out_file \
      --outSAMtype BAM Unsorted \
      --outBAMcompression 0 \
      --alignIntronMax 25000 \
      --genomeLoad LoadAndKeep

    # sort and index the bam
    
    cd $out_dir
    
    samtools sort -m 5G -O BAM --threads 4 ${out_file}Aligned.out.bam > ${out_file}Aligned.out.sorted.bam
    samtools index ${out_file}Aligned.out.sorted.bam
    
    rm ${out_file}Aligned.out.bam


    cd $fastq_dir
    
  done
  
# samples with single ended reads

R_files = $(ls *[!12].fastq)

for f1 in $R_files
  do
    out_file=$(basename $f1 $fastq)_U_
    echo $(date) $f1 ">" $out_file 
    # map the paired reads
    STAR --runThreadN 28 \
      --genomeDir $index_dir \
      --readFilesIn $f1 \
      --outFileNamePrefix $out_dir/$out_file \
      --outSAMtype BAM Unsorted \
      --outBAMcompression 0 \
      --alignIntronMax 25000 \
      --genomeLoad LoadAndKeep

    # sort and index the bam
    
    cd $out_dir
    
    samtools sort -m 5G -O BAM --threads 4 ${out_file}Aligned.out.bam > ${out_file}Aligned.out.sorted.bam
    samtools index ${out_file}Aligned.out.sorted.bam
    
    rm ${out_file}Aligned.out.bam

    cd $fastq_dir
    
  done

  
STAR --genomeLoad Remove --genomeDir $index_dir
```





Count the reads

```{bash}
conda activate sequencing

gff=/analyzed_data/ref_genomes/C_richardii_v2.1/annotation/Crichardii_676_v2.1.gene.gff3
out_file=/home/exouser/git/McConnell-Ceratopteris-RNAseq/NCBI_Samples/output/ht-seq-counts_ncbi.tsv

cd /media/volume/julin-scratch/bams

htseq-count --stranded=no --type=mRNA --idattr=Parent --order=pos *sorted.bam $gff -n 30 > $out_file

# Note that the paired and unpaired reads are counted separately for each file and will need to be combined.
```

## Combine reads
```{r}
samplenames <- read_tsv("../output/bam_names.txt", col_names = "sample_ID") %>%
  mutate(sample_ID=basename(sample_ID),
         sample_ID=str_remove(sample_ID, "_Aligned.*")) %>%
  pull(sample_ID)
samplenames
```


combine paired and unpaired counts
```{r}
counts <- read_tsv("../output/ht-seq-counts_redo.tsv.gz",
                   col_names = c("gene_ID", samplenames))
counts[,1:10]
```

```{r}
counts %>% filter(str_detect(gene_ID, "__"))
```


combine counts for the P and U files
```{r}
counts_combined <- counts %>% 
  pivot_longer(-gene_ID, names_to="sample", values_to="count") %>%
  separate(sample, into=c("sample_ID", "type"), sep = "_") %>%
  group_by(gene_ID, sample_ID) %>%
  summarize(count=sum(count)) %>%
  pivot_wider(names_from = sample_ID, values_from = count)

counts_combined
```
```{r}
write_csv(counts_combined, file = "../output/ht-seq-counts-combined.csv.gz")
```



